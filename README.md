# ğŸ§  Personix AI

### Privacy-Preserving Synthetic Human Dataset Generation Platform

![Python](https://img.shields.io/badge/Python-3.10+-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-Backend-green)
![React](https://img.shields.io/badge/React-Frontend-blue)
![Supabase](https://img.shields.io/badge/Supabase-PostgreSQL-green)
![Vercel](https://img.shields.io/badge/Vercel-Frontend%20Hosting-black)
![License](https://img.shields.io/badge/License-MIT-yellow)

> **Personix AI** is an end-to-end synthetic human dataset generation platform that automatically produces, categorizes, packages, and securely delivers privacy-preserving facial datasets using generative AI models.

The platform behaves like a **synthetic data factory**, enabling researchers and developers to obtain **AI-generated human datasets without collecting real personal images**.

---

# ğŸŒ Live Demo

Frontend
ğŸ‘‰ https://personix-ai.vercel.app

Backend API
ğŸ‘‰ https://personix-api.onrender.com

API Documentation
ğŸ‘‰ https://personix-api.onrender.com/docs

---

# ğŸš€ Project Overview

Training computer vision models typically requires large datasets of human faces.
Using real human data introduces **privacy, legal, and ethical concerns**.

Personix AI solves this by generating **synthetic human faces using GAN models**.

The system automatically:

â€¢ Generates synthetic faces
â€¢ Classifies them by attributes
â€¢ Stores them in categorized inventory
â€¢ Packages datasets on demand
â€¢ Delivers datasets instantly

---

# ğŸ§  Core Idea

Instead of generating faces **when users request them** (which is slow), the system maintains a **pre-generated inventory**.

```mermaid
flowchart LR
A[GAN Generator] --> B[Attribute Classifier]
B --> C[Categorized Inventory]
C --> D[Dataset Packaging]
D --> E[User Download]
```

This allows **instant dataset delivery without GPU inference during requests**.

---

# ğŸ—ï¸ System Architecture

```mermaid
flowchart LR

User --> Frontend[React Frontend]

Frontend --> API[FastAPI Backend]

API --> Database[(Supabase Database)]
API --> Storage[(Object Storage)]

API --> Worker[Dataset Worker]

Worker --> Generator[GAN Model]
Worker --> Classifier[Attribute Classifier]

Generator --> Images[Generated Faces]
Classifier --> Images

Images --> Storage
Storage --> Database

Database --> API
API --> Frontend
Frontend --> User
```

---

# ğŸ”„ Dataset Request Flow

```mermaid
sequenceDiagram
participant User
participant Frontend
participant API
participant Worker
participant Storage

User->>Frontend: Request Dataset
Frontend->>API: POST /dataset/request
API->>Database: Store Request

Worker->>Database: Detect Pending Jobs
Worker->>Storage: Retrieve Images
Worker->>Worker: Package ZIP Dataset

Worker->>Database: Mark Completed
API->>Frontend: Provide Download URL
Frontend->>User: Download Dataset
```

---

# âš™ï¸ System Components

## 1ï¸âƒ£ Frontend Dashboard

Built with **React + Vite + TailwindCSS**

Features:

â€¢ Dataset request interface
â€¢ Request tracking
â€¢ Secure dataset download
â€¢ Bulk dataset request form
â€¢ Admin monitoring dashboard

---

## 2ï¸âƒ£ FastAPI Backend

Handles:

â€¢ dataset request APIs
â€¢ secure downloads
â€¢ request queue management
â€¢ admin analytics endpoints
â€¢ monitoring endpoints

Example endpoints:

| Endpoint                        | Description                |
| ------------------------------- | -------------------------- |
| `/dataset/request`              | Create dataset request     |
| `/dataset/status/{id}`          | Track request              |
| `/dataset/download/{id}/{code}` | Secure dataset download    |
| `/admin/metrics`                | Admin dashboard statistics |
| `/admin/system-status`          | System monitoring          |

---

## 3ï¸âƒ£ Dataset Worker System

Background workers perform heavy operations:

â€¢ dataset packaging
â€¢ inventory refill
â€¢ request queue processing
â€¢ ZIP dataset creation

Workers operate **independently of the API server**.

---

## 4ï¸âƒ£ Synthetic Image Generator

Synthetic faces are generated using **GAN models** such as:

â€¢ StyleGAN2
â€¢ StyleGAN2-ADA

Generation pipeline:

```mermaid
flowchart LR
Z[Latent Vector] --> G[Generator Network]
G --> F[Synthetic Human Face]
```

---

## 5ï¸âƒ£ Attribute Classification

Generated faces are automatically categorized using:

â€¢ DeepFace
â€¢ InsightFace

Extracted attributes:

â€¢ gender
â€¢ age group

This allows images to be organized for dataset requests.

---

# ğŸ“¦ Inventory-Based Dataset System

Traditional GAN APIs generate images per request.

Personix AI uses **inventory-based generation**.

```mermaid
flowchart LR
A[GAN Generator] --> B[Face Classifier]
B --> C[Categorized Storage]
C --> D[Inventory Database]
D --> E[Dataset Packaging Worker]
E --> F[User Download]
```

Benefits:

â€¢ instant response
â€¢ no GPU needed during requests
â€¢ scalable architecture

---

# ğŸ“Š Admin Monitoring System

The admin dashboard monitors system health and usage.

```mermaid
flowchart LR
Scheduler --> MetricsCollector
MetricsCollector --> MetricsCache
MetricsCache --> AdminAPI
AdminAPI --> AdminDashboard
```

Tracked metrics:

â€¢ request queue size
â€¢ completed datasets
â€¢ packaging time
â€¢ download statistics
â€¢ inventory levels

Example monitoring snapshot:

```
{
  "queue": {
    "pending_jobs": 2,
    "completed_jobs": 30
  },
  "performance": {
    "avg_completion_seconds": 1537
  },
  "downloads": {
    "total_downloads": 10
  }
}
```

---

# â˜ï¸ Deployment Architecture

```mermaid
flowchart LR

User --> Vercel[Frontend - Vercel]

Vercel --> Backend[FastAPI - Render]

Backend --> Supabase[(Supabase Database)]
Backend --> Storage[(Cloud Storage)]

Worker --> Storage
Worker --> Supabase
Worker --> Backend
```

---

# ğŸ“‚ Project Structure

```
personix-ai
â”‚
â”œâ”€â”€ api
â”‚   â”œâ”€â”€ server.py
â”‚   â”œâ”€â”€ routes
â”‚   â”‚   â”œâ”€â”€ admin_routes.py
â”‚   â”‚   â””â”€â”€ bulk_routes.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â””â”€â”€ services.py
â”‚
â”œâ”€â”€ workers
â”‚   â”œâ”€â”€ request_worker.py
â”‚   â”œâ”€â”€ package_dataset.py
â”‚   â””â”€â”€ inventory_daemon.py
â”‚
â”œâ”€â”€ monitoring
â”‚   â”œâ”€â”€ metrics_cache.py
â”‚   â”œâ”€â”€ metrics_queries.py
â”‚   â””â”€â”€ health_rules.py
â”‚
â”œâ”€â”€ delivered_datasets
â”‚
â””â”€â”€ frontend
    â””â”€â”€ React dashboard
```

---

# ğŸ› ï¸ Tech Stack

### Backend

Python
FastAPI
Uvicorn

### Frontend

React
Vite
TailwindCSS

### Database

Supabase (PostgreSQL)

### Storage

Cloud Object Storage (R2 / S3)

### Machine Learning

StyleGAN2
StyleGAN2-ADA
DeepFace

---

# â–¶ï¸ Running the Backend

Clone repository

```
git clone https://github.com/sivarajv04/personix-ai.git
cd personix-ai
```

Create virtual environment

```
python -m venv venv
```

Activate environment

Windows

```
venv\Scripts\activate
```

Linux / Mac

```
source venv/bin/activate
```

Install dependencies

```
pip install -r requirements.txt
```

Run FastAPI server

```
uvicorn api.server:app --reload
```

Server

```
http://127.0.0.1:8000
```

API documentation

```
http://127.0.0.1:8000/docs
```

---

# ğŸ” Environment Variables

Create `.env`

```
SUPABASE_URL=
SUPABASE_KEY=
ADMIN_PASSWORD=
STORAGE_BUCKET=
MODEL_PATH=
```

---

# ğŸ§ª Example Use Cases

Personix AI can be used for:

â€¢ computer vision dataset generation
â€¢ privacy-safe AI training data
â€¢ face recognition research
â€¢ GAN research experiments
â€¢ AI benchmarking datasets

---

# ğŸ“ˆ Future Roadmap

Planned improvements:

â€¢ automated GAN retraining pipeline
â€¢ distributed worker cluster
â€¢ dataset marketplace
â€¢ advanced attribute classification
â€¢ GPU generation cluster
â€¢ dataset API rate limiting

---

# ğŸ‘¨â€ğŸ’» Author

**Sivaraj V**

AI Engineer | Machine Learning Engineer | AI Systems Developer

GitHub
https://github.com/sivarajv04

LinkedIn
https://linkedin.com/in/sivarajvofficial

---

# ğŸ“œ License

MIT License

---

â­ If you find this project useful, please **star the repository**.






# ğŸ§  Personix AI

### Intelligent AI Assistant Platform for Personalized Insights

![Python](https://img.shields.io/badge/Python-3.10+-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-Backend-green)
![AI](https://img.shields.io/badge/AI-LLM%20Powered-orange)
![License](https://img.shields.io/badge/License-MIT-yellow)

> **Personix AI** is an AI-powered backend system designed to generate personalized insights, intelligent responses, and contextual automation using modern AI models and scalable API architecture.

The system is designed to power **AI assistants, knowledge systems, automation tools, and intelligent productivity platforms**.

---

# ğŸš€ Overview

Personix AI provides a **modular AI backend architecture** capable of:

* Processing user inputs
* Generating AI-driven responses
* Integrating external AI services
* Providing scalable REST APIs
* Supporting intelligent automation workflows

The project focuses on building **production-ready AI infrastructure** that can be integrated with web apps, mobile apps, and enterprise systems.

---

# âœ¨ Key Features

### ğŸ¤– AI-Powered Intelligence

* Context-aware text processing
* AI-driven response generation
* Personalized insights and recommendations

### âš¡ High Performance Backend

* Built using **FastAPI**
* Asynchronous API handling
* Scalable microservice-ready architecture

### ğŸ”— AI Integration

Supports integration with:

* LLM APIs
* NLP pipelines
* external AI services
* custom machine learning models

### ğŸ§© Modular Architecture

Clean separation between:

* API layer
* AI processing engine
* service layer
* utilities and helpers

This allows the system to remain **maintainable and extensible**.

---

# ğŸ—ï¸ System Architecture

```mermaid
flowchart LR

User[User / Client] --> Frontend[Frontend Application]

Frontend --> API[FastAPI Backend]

API --> Router[API Router]
Router --> Validator[Request Validation]

Validator --> AIEngine[AI Processing Engine]

AIEngine --> Prompt[Prompt Processing]
AIEngine --> Model[AI Model Inference]

Model --> ExternalAI[External AI APIs]

ExternalAI --> PostProcess[Response Post Processing]

PostProcess --> APIResponse[Structured API Response]

APIResponse --> Frontend
Frontend --> User
```

---

# âš™ï¸ Production Deployment Architecture

```mermaid
flowchart LR

User --> CDN[CDN / Edge Network]

CDN --> Frontend[Frontend Application]

Frontend --> Gateway[API Gateway]

Gateway --> Backend[FastAPI Server]

Backend --> AIService[AI Processing Engine]

AIService --> LLM[LLM APIs]

AIService --> Database[(Database)]

AIService --> VectorDB[(Vector Database)]

LLM --> Backend
Database --> Backend
VectorDB --> Backend

Backend --> Gateway
Gateway --> Frontend
Frontend --> User
```

---

# ğŸ§  AI Processing Pipeline

```mermaid
flowchart TD

Input[User Input]
Validate[Input Validation]
Prompt[Prompt Processing]
Inference[AI Model Inference]
PostProcess[Response Processing]
Output[Structured Response]

Input --> Validate
Validate --> Prompt
Prompt --> Inference
Inference --> PostProcess
PostProcess --> Output
```

Steps:

1ï¸âƒ£ User sends request to API
2ï¸âƒ£ Backend validates input
3ï¸âƒ£ Prompt is processed and formatted
4ï¸âƒ£ AI model generates response
5ï¸âƒ£ Response is structured and returned

---

# ğŸ”„ API Request Flow

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant API
    participant AIEngine
    participant AIModel

    User->>Frontend: Submit request
    Frontend->>API: POST /generate
    API->>AIEngine: Process request
    AIEngine->>AIModel: Send prompt
    AIModel-->>AIEngine: AI response
    AIEngine-->>API: Structured output
    API-->>Frontend: JSON response
    Frontend-->>User: Display result
```

---

# ğŸ“‚ Project Structure

```
personix-ai
â”‚
â”œâ”€â”€ app
â”‚   â”‚
â”‚   â”œâ”€â”€ api
â”‚   â”‚   â”œâ”€â”€ routes
â”‚   â”‚   â””â”€â”€ endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ core
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services
â”‚   â”‚   â”œâ”€â”€ ai_engine.py
â”‚   â”‚   â””â”€â”€ processing.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models
â”‚   â”‚
â”‚   â””â”€â”€ utils
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

# ğŸ› ï¸ Tech Stack

### Backend

* Python
* FastAPI
* Uvicorn

### AI / Machine Learning

* LLM APIs
* NLP pipelines
* AI inference services

### Development Tools

* REST API architecture
* modular backend design
* virtual environments

---

# âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/sivarajv04/personix-ai.git
cd personix-ai
```

---

### 2ï¸âƒ£ Create virtual environment

```bash
python -m venv venv
```

Activate it:

**Windows**

```bash
venv\Scripts\activate
```

**Linux / Mac**

```bash
source venv/bin/activate
```

---

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

# â–¶ï¸ Running the Project

Start the FastAPI server:

```bash
uvicorn main:app --reload
```

Server will run at:

```
http://127.0.0.1:8000
```

Interactive API documentation:

```
http://127.0.0.1:8000/docs
```

---

# ğŸ“¡ API Endpoints

| Method | Endpoint    | Description               |
| ------ | ----------- | ------------------------- |
| GET    | `/`         | Health check              |
| POST   | `/generate` | Generate AI response      |
| GET    | `/docs`     | Swagger API documentation |

---

# ğŸ” Environment Variables

Create a `.env` file:

```
OPENAI_API_KEY=your_api_key
AI_MODEL=gpt-4
```

---

# â˜ï¸ Deployment

Personix AI can be deployed on:

### Render

Start command

```
uvicorn main:app --host 0.0.0.0 --port $PORT
```

---

### Docker

```
docker build -t personix-ai .
docker run -p 8000:8000 personix-ai
```

---

### Cloud Platforms

Supported deployment platforms:

* AWS
* Google Cloud
* Azure
* Render
* Railway
* DigitalOcean

---

# ğŸ§ª Example Use Cases

Personix AI can power:

* AI personal assistants
* automated summarization tools
* intelligent chat systems
* productivity automation
* knowledge assistants
* AI-powered customer support bots

---

# ğŸ“ˆ Roadmap

Future enhancements:

* Retrieval-Augmented Generation (RAG)
* Vector database integration
* conversation memory
* user personalization
* streaming AI responses
* authentication system
* frontend dashboard

---

# ğŸ¤ Contributing

Contributions are welcome.

Steps:

```
1 Fork the repository
2 Create a feature branch
3 Commit your changes
4 Open a pull request
```

---

# ğŸ‘¨â€ğŸ’» Author

**Sivaraj V**

AI Engineer | Machine Learning Engineer | AI Systems Developer

GitHub
[https://github.com/sivarajv04](https://github.com/sivarajv04)

LinkedIn
[https://linkedin.com/in/sivarajvofficial](https://linkedin.com/in/sivarajvofficial)

---

# ğŸ“œ License

This project is licensed under the **MIT License**.

---

â­ If you find this project useful, please **star the repository**.

---


